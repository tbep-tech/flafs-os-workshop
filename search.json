[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Florida AFS 2023 Open Science Workshop",
    "section": "",
    "text": "Course synopsis\nWelcome to the 2023 Florida AFS open science workshop! Open science (OS) has been advocated as an effective approach to create reproducible, transparent, and actionable research products. However, widespread adoption among the research and management community has not occurred despite its perceived benefits. In the face of major environmental challenges, the collaborative framework provided by OS is needed now more than ever. This workshop will cover material introducing participants to core concepts of OS. The target audience includes anyone interested in applying OS in their own workflows as part of a larger research and resource management team.\nBy the end of this workshop, you should have a good understanding of fundamental concepts in open science and how they can be applied to help bridge the research-management divide. You will also have the skills to understand how collaborative open science tools can be used to increase efficiency and transparency, understand fundamental best practices for working with data to facilitate openness, and create reproducible Quarto documents.\nMuch of the content on this web page was adopted from the TBEP Data Management SOP."
  },
  {
    "objectID": "index.html#prepare",
    "href": "index.html#prepare",
    "title": "Florida AFS 2023 Open Science Workshop",
    "section": "Prepare",
    "text": "Prepare\nPlease attend the workshop with a personal laptop and power supply. Make sure your laptop can access publicly available WiFi. You need to install software prior to the workshop, visit the setup page for full instructions. We will have limited capacity to help with installation issues the day of the workshop, so please come prepared. The setup instructions will guide you through the following.\n\nInstall R: link\nInstall RStudio: link\nInstall Quarto: link\nGitHub create account: link\nInstall Git (optional): link\n\nWe also assume some knowledge about R. Please visit this page for a crash course if you need to brush up on your R skills."
  },
  {
    "objectID": "index.html#agenda",
    "href": "index.html#agenda",
    "title": "Florida AFS 2023 Open Science Workshop",
    "section": "Agenda",
    "text": "Agenda\n\nThe basics of open science: 12:30 - 1:00\nOpen science for collaboration: 1:00 - 2:00\nOpen science for impactful products: 2:15pm - 3:30pm\n\nEach module uses a set of common icons to orient you to specific tasks or experiences during this workshop. These include the following:\n\n Exercise and discussion\n\n\n Watch and learn\n\n\n Description of a collaborative tool\n\n\n Pros of a collaborative tool or solution to an open science challenge\n\n\n Cons of a collaborative tool\n\n\n Challenge to overcome for open science"
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Florida AFS 2023 Open Science Workshop",
    "section": "Instructor",
    "text": "Instructor\nDr. Marcus Beck is the Program Scientist for the Tampa Bay Estuary Program and is developing data analysis and visualization methods for Bay health indicators. He received his PhD in Conservation Biology from the University of Minnesota in 2013. Marcus has experience researching environmental indicators and developing open science products to support environmental decision-making. Marcus is also an open source software and dashboard developer to facilitate science application. CV, Google Scholar, GitHub\n\n  This website is licensed under a Creative Commons Attribution 4.0 International License.\n This version of the website was built automatically with GitHub Actions on 2023-05-08."
  },
  {
    "objectID": "basics.html#goals-and-motivation",
    "href": "basics.html#goals-and-motivation",
    "title": "1  Open science basics",
    "section": "1.1 Goals and motivation",
    "text": "1.1 Goals and motivation\nThis is the first module in our workshop on open science. This module describes the need for open science, how it can improve research applications, and exposes you to common ideas and terminology that we’ll be using throughout the day. Consider this your 30,000 foot view of open science. Our later modules will provide more detail on specific topics in open science that you can use for continued learning.\n\nGoal: get comfortable with key ideas and concepts for understanding open science\nMotivation: this is the first step in your open science journey!"
  },
  {
    "objectID": "basics.html#why-open-science",
    "href": "basics.html#why-open-science",
    "title": "1  Open science basics",
    "section": "1.2 Why open science?",
    "text": "1.2 Why open science?\nLet’s start with revisiting the scientific process. I’m sure this looks familiar to all of you. This is geared towards an applied research question.\n\n\n\n\n\nOur basic scientific approach to discovery is motivated by a question or research goal, developing a hypothesis for the question, collecting data based on the hypothesis, developing a tool that can be used for decision-making, and summarizing the results in a conventional format.\nMany scientists, especially early career researchers (my past self included), may assume that this is sufficient to affect change. We write the report, send it out into the world, and move on to the next project. This is a common mentality:\n\n“This 500-page report will answer all of their questions!”\n\nFrom the other side, such as the manager or policy-maker, the report may be received like this:\n\n“This 500-page report answers none of my questions!”\n\nIt’s dense, inaccessible, and there are probably questions about the underlying data and methods used to achieve the results. More importantly, it doesn’t present the information in an easily digestible format to quickly make the right decision. Sometimes, if you think you’re doing applied science, it may just be implied science that falls short of application.\nWhy is this conventional approach to science ineffective at seeding change?\nThe environmental management community is often siloed with each branch doing their own thing and speaking their own language. Between the research (typically academic) and management community, we call this the research-management divide.\n\n\n\n\n\nA distinct gap exists between how scientific products are developed and how they can be used to meet management needs. This is often the result of communication barriers, irreproducible results, information loss with poor documentation, inaccessible data, and opaque workflows known only to the analyst.\nThese barriers can occur at any stage of the research process. This compelling graphic from Michener et al. (1997) describes the atrophy of information in a closed approach to creating science.\n\n\n\n\n\nThe last part is especially morbid. Sometimes, this is called the “bus factor”. What would happen to your important work and life achievements if you were hit by a bus? Would others be able to pick it up? Research products with a high bus factor are at risk of being lost if critical team members are no longer available. This is a very real problem for continuity of science.\n\n\n\n\n\nSo how do we make changes to our workflows to ensure we can achieve truly applied science using open tools and philosophies?"
  },
  {
    "objectID": "basics.html#learning-and-speaking-the-language-of-open-science",
    "href": "basics.html#learning-and-speaking-the-language-of-open-science",
    "title": "1  Open science basics",
    "section": "1.3 Learning and speaking the language of open science",
    "text": "1.3 Learning and speaking the language of open science\nThe tools and broader philosophy behind open science can help us bridge the research-management divide. It involves a fundamental shift in how we approach the scientific process, both for your own internal workflows and how you can engage others in the process. By others, we mean not just researchers, but specifically those that need the information to make informed decisions. This also includes your future self.\nNow, let’s settle on a definition for open science (from Open Knowledge International, http://opendefinition.org/, https://creativecommons.org/):\n\n“The practice of science in such a way that others can collaborate and contribute, where research data, lab notes and other research processes are freely available, under terms that enable reuse, redistribution and reproduction of the research and its underlying data and methods.”\n\nKey words from this definition are italicized. There are very specific tools in the open science toolbox that enable each of these key words. We’ll cover some of these later.\nSimilarly, the current administration has declared 2023 the Year of Open Science. Their definition is:\n\n“The principle and practice of making research products and processes available to all, while respecting diverse cultures, maintaining security and privacy, and fostering collaborations, reproducibility, and equity.”\n\nWe can can breakdown these definitions into key principles.\n\n Open data\n\nPublic availability of data\nReusability and transparent workflows\nData provenance and metadata\n\n Open process\n\nIterative methods using reproducible workflows\nCollaboration with colleagues using web-based tools\nLeveraging external, open-source applications\n\n Open products\n\nInteractive web products for communication\nDynamic documents with source code\nIntegration with external networks for discoverability\n\n\nYou’ll notice that web-based tools and open science are often discussed at the same time. Science existed before the internet. Open science often focuses on how the two can leverage and support one another despite the latter being a relatively new addition to society.\nAdvocates of open science also use the FAIR principles (Wilkinson et al. 2016) as guidelines. The FAIR acronym stands for Findable, Accessible, Interoperable, and Reusable. Anybody should be able to find your science, access it once it’s found, use it in different environments, and reproduce it for additional analysis."
  },
  {
    "objectID": "basics.html#schools",
    "href": "basics.html#schools",
    "title": "1  Open science basics",
    "section": "1.4 Schools of thought",
    "text": "1.4 Schools of thought\nFinally, it’s useful to make a distinction of how different people may talk about open science. This can help you better navigate conversations and become an advocate for open science in your own right.\nA useful paradigm is provided by Fecher and Friesike (2014) that describes open science as five distinct schools of thought:\n\n\n\n\n\nThese are of course only conceptual boxes and there’s considerable overlap across all schools when open science is used in practice. For our purposes, we’ll mostly be talking about ideas and tools from the pragmatic, infrastructure, and democratic schools of thought. The end goal is to provide you with the means to create more efficient and impactful science that can more readily be used by others in a collaborative setting.\n\n\n\n\nFecher, B., and S. Friesike. 2014. “Open Science: One Term, Five Schools of Thought.” In Opening Science, 17–47. Springer, Cham.\n\n\nMichener, W. K., J. W. Brunt, J. J. Helly, T. B. Kirchner, and S. G. Stafford. 1997. “Nongeospatial Metadata for the Ecological Sciences.” Ecological Applications 7 (1): 330–42. https://doi.org/https://doi.org/10.1890/1051-0761(1997)007[0330:NMFTES]2.0.CO;2.\n\n\nWilkinson, M. D., M. Dumontier, I. J. Aalbersberg, G. Appleton, M. Axton, A. Baak, N. Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” Scientific Data 3 (160018). https://doi.org/10.1038/sdata.2016.18."
  },
  {
    "objectID": "collaborate.html#goals-and-motivation",
    "href": "collaborate.html#goals-and-motivation",
    "title": "2  Open science for collaboration",
    "section": "2.1 Goals and motivation",
    "text": "2.1 Goals and motivation\nThis is the second module in our workshop on open science. This module will explore some open science tools to help you and your team become better collaborators and to better engage your science with external partners. We’ll introduce some essential elements of collaboration and discuss some readily available tools for doing so.\n\nGoal: understand methods of collaboration and the pros/cons of various tools\nMotivation: start building the tools for your open science toolbox"
  },
  {
    "objectID": "collaborate.html#essential-elements-of-collaboration",
    "href": "collaborate.html#essential-elements-of-collaboration",
    "title": "2  Open science for collaboration",
    "section": "2.2 Essential elements of collaboration",
    "text": "2.2 Essential elements of collaboration\nWe start our deep dive into open science by focusing on collaboration as a fundamental activity that can be enhanced through transparent, efficient, and reproducible tools. Having effective tools to work together is a critical theme of many open science practices.\n\n2.2.1 Workflow management\nHow do you organize your work each day? How do you make sure projects are on schedule and pressing deadlines are met? How do you plan for short-term and long-term goals? Do you have a five-year, ten-year, or longer career plan?\nWork to achieve goals cannot be accomplished without a systematic approach to organizing tasks. Chances are, we each have our own system that works for us and was probably developed through trial and error. Although everyone has familiar workflows, they are often idiosyncratic and deeply entrenched by habit. These comfortable workflows can be in direct conflict with collaboration when we try to mesh them with the habits of others.\nDoes this look familiar?\n\n\n\n\n\n\n\n\n\nAlthough the above comic from xkcd speaks directly to file management, it hints at a broader problem of personal information management that can seriously complicate working with others. I’m sure we’ve all struggled to find that one file for that one project from a vague recollection of seeing it a few months ago.\nCollaborative work can be facilitated through workflow management that helps you break out of old habits. We’ll introduce some specific internet-based tools below to facilitate workflows either for yourself or, better yet, working with others. These can help propel you towards open science.\n\n\n2.2.2 Version control\nA specific problem for workflow management that can be solved by open science tools is file management. Workflows can be immensely enhanced by tools that use strict guidelines for tracking changes and allowing a complete view of the evolution of a project. This is where version control comes in.\nI’m sure many of you have fallen into this trap:\n\n\n\n\n\n\n\n\n\nVersion control is a way to track the development history of a project. It serves the joint purposes of:\n\nFormally documenting the changes that have been made to code or software\nMaking sure that the development history is permanent\nProviding a system for collaborating across platforms (with friends!)\n\nIt’s more than saving files. Documenting changes with a set of commands that follow strict rules provides a transparent record for yourself and others, and establishing permanency ensures that any of the changes that are made can be vetted and accessed as needed. Think of it as an insurance plan for your project.\nIf you’ve ever used Google Docs, you might have noticed a feature that looks a lot like version control. The Google Drive platform is a great way to start working together and to familiarize yourself with the basics of version control.\n\n\n\n\n\n\n\n\n\nFor any Google Doc, clicking on the link shown by the arrow will open the Version history pane which shows all of the edits that were made to the document. You can view any of the edits, who made the edits, view the changes (before/after) in the document, or even restore the document to a previous version.\n\n\n\n\n\n\n\n\n\nThese are the building blocks of version control as demonstrated with Google Docs:\n\nNo iterative and ambiguous file naming\nHistory of changes assigned to each editor\nAbility to restore a previous version\n\nPerhaps more importantly, these tools are in the cloud and openly accessible (unlike other cloud-based services). File links (via a URL) also do not change if a file is moved to a different location in the drive. Overall, the Google platform is an accessible means of improving collaboration (but not without cons).\n\n\n2.2.3 Git and GitHub\nAlthough Google products can get you a long way towards better collaboration, they do not use dedicated version control software. These tools become more important as your projects become more complex - those beyond simple documents or spreadsheets.\nThe most widely used software for version control is Git. Although we do not cover the specifics of this software, it’s useful to understand the purpose and what it can do in making your work more open and impactful. Git is integrated with many popular open source development platforms, such as RStudio.\nMany people often confuse Git with GitHub. GitHub is an online platform for working collaboratively through Git AND it allows you to be open with your work. We’ll provide some examples below of how this can be done. Importantly, you do not need to be an expert in Git to be able to use GitHub. This speaks volumes for how team efficiency can be improved with GitHub through better collaboration.\nThis recent blog provides a helpful introduction to Git/GitHub for the casual user.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctocat, the strange and loveable mascot of GitHub.\n\n\n\n\n\n Watch and learn\n\nWorkflow management in the real world - using GitHub to collaborate. Here we present some examples from the Tampa Bay Estuary Program State of the Bay report and water quality report card.\n\n Watch and learn\n\nNow we’ll demonstrate how to setup a version control project with RStudio, Git, and GitHub. This example will cover:\n\nCreating the project in GitHub\nCreating a file, adding content, and committing it to the project\nSetting up issues in GitHub\nAdding members to the project\nCreating a Kanban project board to assign tasks\n\n\n Exercise and discussion\n\nIn small groups, setup a shared workspace using GitHub and create a project management board. Some real world examples of why you might do this were presented in the earlier watch and learn.\n\nOpen GitHub in a web browser and have one person create a new repository (the big, green “New” button in Repositories). Add each member to the repository after it’s created (hint: Settings -&gt; Collaborators)\nHave that same person create a project board for the repository (Hint: Projects -&gt; New project -&gt; board format)\nAfter each person accepts the invitation to the repository (check your email!), each new member create a new file in the repository (Hint: Click “Add file” near the top). Name it something unique, save and commit the changes\nAssign issues to different members of the repository to do something to the new files (Hint: on the right menu, select “Assignees”). Add the issue to the project board (Hint: on the right menu, select “Projects” and click the new project).\nWork on the issues until the time is up. Close each issue as they’re completed."
  },
  {
    "objectID": "impact.html#goals-and-motivation",
    "href": "impact.html#goals-and-motivation",
    "title": "3  Open science for impactful products",
    "section": "3.1 Goals and motivation",
    "text": "3.1 Goals and motivation\nThis is the third module in our workshop on open science. Now we focus on how Quarto can be used as a document preparation system to generate easily shared web content.\n\nGoal: understand best practices for reproducible documents using Quarto\nMotivation: cultivate your analyses as living, shared resources"
  },
  {
    "objectID": "impact.html#quarto",
    "href": "impact.html#quarto",
    "title": "3  Open science for impactful products",
    "section": "3.2 Quarto",
    "text": "3.2 Quarto\nQuarto is a relatively new document preparation system that lets you create reproducible and dynamic content that is easily shared with others. Quarto is integrated with RStudio and allows you to combine plain text language with analysis code in the same document.\nQuarto belongs to a class of reporting tools called dynamic documents or literate programming (Knuth 1984). It is not the first of its kind, but it builds substantially on its predecessors by bridging multiple programming langues.\nAdvantages of creating analyses using Quarto include:\n\nClear demonstration of a workflow using plain text and code\nReproducible materials allow others to use your work\nEasily shared content (e.g., on GitHub)\nKeeping the data, analysis, and writing all in the same place\n\nThis next section will run through the very basics of creating a Quarto document, some of the options for formatting, and how to generate shared content. You’ll follow along in this module.\n\nCreate a new project in RStudio, first open RStudio and select “New project” from the File menu at the top.\n\n\n\n\n\nThen select “New Directory”. Create a directory in a location that’s easy to find.\n\n\n\n\n\nOpen a new Quarto file from the File menu under New file &gt; Quarto Document.\n\n\n\n\n\nEnter a title for the document (e.g., “Quarto practice”) and your name as the author. Use the defaults for the other options and hit “Create”.\n\n\n\n\n\nSave the file in the project root directory (give it any name you want).\nLet’s get familiar with the components of a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nThe three main components of a Quarto document are:\n\nYAML\nCode chunks\nPlain or Markdown text\n\n\n\nThe new file is completely empty except for the title, name, and editor type at the top. The content at the top is called YAML, which defines global options for the document.\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\n---\nYou’ll also notice that there’s a button on the top-left that lets you toggle between “source” or “visual” editor mode. The source editor simply lets you add text to the document, whereas the visual editor lets you add content that is partially rendered. First time Quarto users may prefer the visual editor.\n\n\n\n\n\nUsing the visual editor, we can insert a code chunk (or code cell). This can be done by selecting the appropriate option from the Insert menu. Note the variety of programming langues that can be used with the code chunk.\n\n\n\n\n\nWe can enter any code we want in the code chunks, including options for how the code chunk is evaluated. Options are specified using the hashpipe notation, #|.\n```{r}\n#| echo: true\nprint('Hello Quarto!')\n```\nWhen the file is rendered, the code is run and results displayed in the output. There are many options to change how code chunks are executed, which we’ll discuss below.\n\nprint('Hello Quarto!')\n\n[1] \"Hello Quarto!\"\n\n\nWe can also run the code chunks separately without rendering the file using the arrow buttons on the top right in the source document. This can be useful for quickly evaluating your code as you include it in the file.\n\n\n\n\n\n\nTip\n\n\n\nCode chunks are executed in the order they appear in the document when a .qmd file is rendered.\n\n\nDescriptive text can be entered anywhere else in the file. This is where we can describe in plain language what our analysis does or any other relevant information. Text can be entered as-is or using simple markdown text that can format the appearance of the output. If you’re using the visual editor, you can use some of the items in the file menu to modify the text appearance. In the source editor, you can manually enter markdown text:\n\n\nI  can write anything I want right here. Here's some **bold text**.\n\nI can also make lists\n\n1. Item 1\n1. Item 2\n\n\n\nWhen the file is rendered, the markdown text will be formatted. The text will already be formatted if you’re using the visual editor:\n\nI can write anything I want right here. Here’s some bold text.\nI can also make lists\n\nItem 1\nItem 2\n\n\nRender the .qmd file to the output format.\nThe source file is a .qmd document. We need to render the document to create the output format - HTML (default), PDF, or Word. The following happens when you hit the render button at the top.\n\n\n\n\n\nHere’s what your RStudio session should look like (note the three parts of the source .qmd document - YAML, code chunk, and Markdown text). The rendered HTML file will appear in the Viewer pane on the right.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nA rendered Quarto document as an HTML, PDF, Word, or other file format is stand-alone and can be shared with anybody!\n\n\n\n\n3.2.1 Code chunk options\nThe behavior of the code chunks when the file is rendered can be changed using the many options available in Quarto. This can be useful for a few reasons.\n\nOnly displaying the output of a code chunk\nOnly displaying the code and not running the chunk\nRunning the code without displaying output for use in other parts of the document\nSuppressing warnings and messages\nDefining table or figure options (e.g., height, width, captions, etc.)\n\nCode chunk options can be applied globally to all chunks in the document or separately for each chunk.\nTo apply them globally, they’ll look something like this in the YAML, where options are added after execute:\n---\ntitle: \"My Document\"\n\nexecute: \n  echo: false\n  warning: false\n---\n\n\n\n\n\n\nTip\n\n\n\nBe careful with indentation in the YAML, the document won’t render if the indentation is incorrect.\n\n\nTo apply to individual code chunks, use the #| (hashpipe) notation at the top of the code chunk. This will override any global options if you’ve included them in the top YAML. Below, echo: true indicates that the code will be displayed in the rendered output.\n```{r}\n#| echo: true\nplot(1:10)\n```\nHere’s a short list of other useful execution options:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output (note that this implies that errors executing code will not halt processing of the document).\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\nmessage\nInclude messages in rendered output\n\n\n\nR code can also be executed “inline” outside of code chunks. This can be useful if you want to include statements that reference particular values or information that is linked directly to data. Inline R code is entered using the r syntax.\n\n\nI can enter inline text like `r 1 + 1`.\n\n\n\nText with inline R code will look like this when the document is rendered.\n\nI can enter inline text like 2.\n\n\n\n3.2.2 Figures and tables\nFigures and tables are easily added in Quarto, using either R code or importing from an external source.\nAny figures created in code chunks will be included in the rendered output. Relevant code chunk options for figures include fig-height, fig-width, fig-cap, label (for cross-referencing) and fig-align.\n```{r}\n#| label: fig-myhist\n#| fig-height: 4\n#| fig-width: 6\n#| fig-cap: \"Here's my awesome histogram.\"\n#| fig-align: \"center\"\nvals &lt;- rnorm(100)\nhist(vals)\n```\n\n\n\n\n\nFigure 3.1: Here’s my awesome histogram.\n\n\n\n\nFigures can be cross-referenced in the text using the @ notation with the figure label.\nHere's a cross-reference to @fig-myhist.\nWhen the file is rendered, the appropriate figure number will be displayed with a link to the figure:\n\nHere’s a cross-reference to Figure 3.1.\n\nSimilarly, tabular output can be created inside code chunks.\n```{r}\n#| label: tbl-mytable\n#| tbl-cap: \"Here's my awesome table.\"\ntotab &lt;- data.frame(\n  Species = c('Bluegill', 'Largemouth bass', 'Crappie'),\n  Count = c(12, 5, 4)\n)\nknitr::kable(totab)\n```\n\n\n\n\nTable 3.1: Here’s my awesome table.\n\n\nSpecies\nCount\n\n\n\n\nBluegill\n12\n\n\nLargemouth bass\n5\n\n\nCrappie\n4\n\n\n\n\n\n\nAnd a cross-reference:\nHere's a cross-reference to @tbl-mytable.\n\nHere’s a cross-reference to Table 3.1.\n\n\n\n\n\n\n\nTip\n\n\n\nLabel tags for tables and figures should include the tbl- or fig- prefix for proper cross-referencing.\n\n\nFigures can also be imported from an external source (e.g., from your computer or the web) using the ![]() notation, where the image is in the img folder in my working directory. You can also simply add a figure from the file menu using the Visual editor.\n![](img/blackcrappie.jpg)\n\n\n\n\n\nYou can also add a figure from a URL using the same notation.\n![](https://www.bigcatchflorida.com/media/1174/blackcrappie.jpg)\n\n\n\n\n\nAdding captions and labels to external figures looks something like this:\n![Here's a beautiful crappie](img/blackcrappie.jpg){#fig-crappie}\n\n\n\nFigure 3.2: Here’s a beautiful crappie\n\n\nThe cross-reference is done the same.\nHere's a cross-reference to @fig-crappie\n\nHere’s a cross-reference to Figure 3.2.\n\nLikewise, tables can be imported from an external source (e.g., Excel). You’ll want to do this in a code chunk and add the appropriate options (e.g., to cross-reference Table 3.2).\n```{r}\n#| label: tbl-habitats\n#| tbl-cap: \"The first six rows of our tidy data\"\nmytab &lt;- readxl::read_excel('data/tidy.xlsx')[1:6, ]\nknitr::kable(mytab)\n```\n\n\n\n\nTable 3.2: The first six rows of our tidy data\n\n\nLocation\nHabitat\nYear\nAcres\nCategory\n\n\n\n\nClear Bay\nSeagrass\n2019\n519\nB\n\n\nClear Bay\nOysters\n2019\n390\nB\n\n\nClear Bay\nSand\n2019\n742\nC\n\n\nFish Bay\nSeagrass\n2019\n930\nB\n\n\nFish Bay\nOysters\n2019\n680\nA\n\n\nFish Bay\nSand\n2019\n611\nA\n\n\n\n\n\n\nVisit these links for full details on figures and tables in Quarto. R also has a rich library of packages for producing tables, most of which play nice with Quarto.\n\n\n3.2.3 Output options\nRendering a Quarto file to an HTML, PDF, or Word document is as simple as adding the appropriate option to the YAML. This is done by choosing the format when you create a new Quarto file:\n\n\n\n\n\nThe output format can also be added in the YAML of the document.\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\nformat: html\n---\n\n\n\n\n\n\nTip\n\n\n\nThe default output format is HTML and it does not need to be added explicitly to the YAML.\n\n\nAlternative formats are specified the same way (i.e., Word and PDF).\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\nformat: docx\n---\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\nformat: pdf\n---\nYou can also specify multiple formats (note the indentation). The default setting just indicates that we want to use all default options for each format and this option must be included.\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\nformat: \n  html: default\n  docx: default\n  pdf: default\n---\nYou can use the dropdown menu to render each file format one at a time. The dropdown menu will show the options that are included in the YAML.\n\n\n\n\n\nYou can also render all formats at once using the quarto package in the console. The path to your file will differ depending on where it is in your working directory.\nquarto::quarto_render('data/quartoex.qmd')\nOr you can render all formats at once using the render command in the terminal (terminal tab, bottom left pane of RStudio). This requires the separate installation of Quarto described in the setup. This is the Quarto Command Line Interface (CLI).\n\n\nTerminal\n\nquarto render data/quartoex.qmd\n\nRendering a file to PDF uses LaTeX and you’ll need to install tinytex before you can use this option. This can also be done in the terminal.\n\n\nTerminal\n\nquarto install tool tinytex\n\nThere are several options you can include in the YAML to control the formatting of the output. Some of the options apply to all format types, whereas others are specific to a type. Here’s an example building out these options.\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\ntoc: true \nnumber-sections: true\nformat: \n  html: \n    code-fold: true\n  docx: default\n  pdf: \n    geometry: \n      - top=30mm\n      - left=0mm\n---\nIn the above example, there are two new options that apply globally to the HTML, Word, and PDF outputs. Specifically, we’ve indicated that we’d like a table of contents (toc: true) and that the sections should be numbered (number-sections: true) in the rendered documents.\nWe’ve also added some specific options to the HTML and PDF output. For the HTML output, we’ve indicated that we want the code chunks to be folded (i.e., toggle between seen and not seen, code-fold: true). For the PDF output, we’ve changed the geometry of the margins using the geometry options.\nHere’s what the HTML output would look like:\n\n\n\n\n\nThere are many other options available for each output format, as well as other format types. View the full list here.\n\n\n3.2.4 Citations and References\nOne of the more valuable aspects of Quarto is the ability to easily add and reference other works in your document. This includes finding papers and reports, citing them in your document, and formatting references - all with relative ease in Quarto.\nYou can of course do this using the source editor, but it’s slightly easier using the visual editor. If we switch to visual mode (top-left button of the .qmd file), you can type a forward-slash to view a menu of items to insert in the document. Just start typing text to search items to insert.\n\n\n\n\n\n\nTip\n\n\n\nThe Insert Anything tool in the visual editor is useful to… insert anything! Just execute / at the beginning of a line or Ctrl/Cmd + / after some text.\n\n\n\n\n\n\n\nYou can also insert a citation from the menu at the top of the .qmd file.\n\n\n\n\n\nEither option will open the citation menu where you can add citations from a variety of sources (ie., Zotero, DOI, CrossRef, PubMed, or DataCite).\nFor example, we can copy/paste a DOI to find a reference of interest.\n\n\n\n\n\nOr we can search by title.\n\n\n\n\n\nOnce the paper is found, you can click the Insert button to add it to your document. This adds a reference file, information in the YAML, and the in-text citation. The reference file will be called references.bib by default and includes a BibTeX formatted reference that looks like this:\n@article{shafland1982,\n    title = {Lower lethal temperatures for fourteen non-native fishes in Florida},\n    author = {Shafland, Paul L. and Pestrak, James M.},\n    year = {1982},\n    month = {03},\n    date = {1982-03},\n    journal = {Environmental Biology of Fishes},\n    pages = {149--156},\n    volume = {7},\n    number = {2},\n    doi = {10.1007/bf00001785},\n    url = {http://dx.doi.org/10.1007/BF00001785},\n    langid = {en}\n}\nThe YAML file will now indicate the reference file to use that includes the references (bibliography: references.bib).\n---\ntitle: \"Quarto practice\"\nauthor: \"Marcus Beck\"\neditor: visual\nbibliography: references.bib\ntoc: true \nnumber-sections: true\nformat: \n  html: \n    code-fold: true\n  docx: default\n  pdf: \n    geometry: \n      - top=30mm\n      - left=0mm\n---\nThe text citation will look like this, where @ is the tag used to reference the citation using the identifier from the references file.\nMany non-native species in Florida have lower lethal temperatures [@shafland1982].\nWhen the Quarto file is rendered, the citation will be formatted and you’ll see it added to the references section at the end of the document.\n\nMany non-native species in Florida have lower lethal temperatures (Shafland and Pestrak 1982).\n\n\n\n\n\n\nThe @ citation syntax also has different options for displaying the citation in the text (full explanation here). For example, omitting the brackets does the following:\n@shafland1982 state that many non-native species in Florida have lower lethal temperatures.\n\nShafland and Pestrak (1982) state that many non-native species in Florida have lower lethal temperatures.\n\nAdditional information about citations in Quarto can be found here.\n\n\n3.2.5 Publishing\nA rendered Quarto file can be shared with anyone as a standalone document. The file can also be hosted online and shared by URL. This latter approach is useful to make the document available to anyone with the web address.\nThe easiest way to do this is to publish your document to RPubs, a free service from Posit for sharing web documents. Click the  publish button on the top-right of the editor toolbar. You will be prompted to create an account if you don’t have one already.\nThis can also be done using the quarto R package in the console.\nquarto::quarto_publish_doc(\n  \"data/quartoex.qmd\", \n  server = \"rpubs.com\"\n  )\nYou can also use the Quarto CLI in the terminal. Here we are publishing the document to Quarto Pub.\n\n\nTerminal\n\nquarto publish quarto-pub data/quartoex.qmd\n\nIf your Quarto document is in an RStudio project on GitHub, you can also publish to GitHub Pages.\n\n\nTerminal\n\nquarto publish gh-pages data/quartoex.qmd"
  },
  {
    "objectID": "impact.html#summary",
    "href": "impact.html#summary",
    "title": "3  Open science for impactful products",
    "section": "3.3 Summary",
    "text": "3.3 Summary\nIn this module we learned the basics of creating dynamic documents with Quarto that combine markdown text with R code. There’s much, much more Quarto can do for you. Please visit https://quarto.org/ for more information on how you can use these documents to fully leverage their potential for open science.\n\n\n\n\nKnuth, Donald Ervin. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nShafland, Paul L., and James M. Pestrak. 1982. “Lower Lethal Temperatures for Fourteen Non-Native Fishes in Florida.” Environmental Biology of Fishes 7 (2): 149–56. https://doi.org/10.1007/bf00001785."
  },
  {
    "objectID": "tidy.html",
    "href": "tidy.html",
    "title": "4  Principles of tidy data",
    "section": "",
    "text": "Tabular data allow you to store information, where observations are in rows and variables are in columns. It’s very common to try to make tabular data more than it should be. Unless you spend a lot of time working with data, it can be difficult to recognize common mistakes that lead to table abuse.\nBefore we get into tidy data, we need to discuss some of the downfalls of Excel as a data management system. There are many examples that demonstrate how Excel has contributed to costly mistakes through table abuse or outright negligence, often to the detriment of science (Ziemann, Eren, and El-Osta 2016).\n\n\n\n\n\n\n\n\n\nExcel allows you to abuse your data in many ways, such as adding color to cells, embedding formulas, and automatically formatting cell types. This creates problems when the organization is ambiguous and only has meaning inside the head of the person who created the spreadsheet. Embedding formulas that reference specific locations in or across spreadsheets is also a nightmare scenario for reproducibility.\n\n\n\n\n\n\n\n\n\nIf you absolutely must use Excel to store data, the only acceptable format is a rectangular, flat file. This is typically saved as a .csv file. What do we mean by this?\nA rectangular file:\n\nStore data only in rows and columns in matrix format (e.g., 10 rows x 5 columns), with no “dangling” cells that have values outside of the grid or more than one table in a spreadsheet.\n\nA flat file:\n\nNo cell formatting, no embedded formulas, no multiple spreadsheets in the same file, and data entered only as alphanumeric characters.\n\nBroman and Woo (2018) provide an excellent guide that expands on these ideas. Essentially, these best practices force you to isolate the analysis from the data - many people use Excel to mix the two, leading to problems.\nNow we can talk about tidy data. The tidy data principles developed by Hadley Wickham (Wickham 2014) are a set of simple rules for storing tabular data that have motivated the development of the wildly popular tidyverse suite of R packages (Wickham et al. 2019). The rules are simple:\n\nEach variable must have its own column;\nEach observation must have its own row; and,\nEach value must have its own cell.\n\nGraphically, these rules are shown below (from Wickham and Grolemund 2017):\n\n\n\n\n\n\n\n\n\nThe following examples show five tables represented in different arrangements. Only one of the tables is tidy - which one?\n\n\n\n\n\nTable 1\n\n\n\n\n\n\n\n\n\nTable 2\n\n\n\n\n\n\n\n\n\nTable 3\n\n\n\n\n\n\n\n\n\nTable 4a\n\n\n\n\n\nTable 4b\n\n\n\n\nOnly the first table is tidy - each variable has its own column, each observation has its own row, and each value has its own cell. Table 2 violates the first rule, Table 3 violates the third rule, and tables 4a and 4b violate the first and second rules.\n\n Exercise and discussion\n\nDownload this untidy dataset and make it tidy using your preferred software.\n\n\n\n\nBroman, K. W., and K. H. Woo. 2018. “Data Organization in Spreadsheets.” The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989.\n\n\nWickham, H. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 1–23. https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D’Agostino McGowan, R. François, G. Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, H., and G. Grolemund. 2017. R for Data Science. Sebastopol, California: O’Reilly.\n\n\nZiemann, M., Y. Eren, and A. El-Osta. 2016. “Gene Name Errors Are Widespread in the Scientific Literature.” Genome Biology 17 (1): 1–3. https://doi.org/10.1186/s13059-016-1044-7."
  },
  {
    "objectID": "implement.html#goals-and-motivation",
    "href": "implement.html#goals-and-motivation",
    "title": "5  Addressing implementation barriers",
    "section": "5.1 Goals and motivation",
    "text": "5.1 Goals and motivation\nWhat does it mean to use open science in the real world? It’s great to talk about the value of open science and the tools you can use, but it’s a completely different ball game when it comes to putting these ideas into practice. Our goal is that you leave this workshop an advocate and early adopter for the ideas we discussed today - spread these ideas to your peers and colleagues! To realistically achieve this goal, we will talk about some of the challenges you will face so you can develop a realistic expectation of what’s to come.\n\nGoal: Understand common hurdles in adopting open science and how to overcome them\n\nMotivation: Become the “open science” expert at your institution!"
  },
  {
    "objectID": "implement.html#learning-curves",
    "href": "implement.html#learning-curves",
    "title": "5  Addressing implementation barriers",
    "section": "5.2 Learning curves",
    "text": "5.2 Learning curves\n\n\n\n\n\n\n\n\n\n\n Challenge\n\nIt’s hard to learn new tools!\n\n Solution\n\nIt’s an investment, look to the community!\nYou’ve probably seen a graphic like this if you’ve ever taken a course in R or Python. The hope is that you’re able to quickly reach the land of sunshine and bunnies, but the path is treacherous and even insurmountable for some.\nA huge obstacle in using open science is that the toolsets can have steep learning curves. More popular platforms, such as Excel, are used by many because they’re simple and intuitive. However, as noted earlier, FAIR workflows and tools are sacrificed for ease of use.\nAlthough it’s true that adopting new tools will slow forward progress, this is only temporary. Consider your path towards learning new platforms an investment in your future. The immediate benefit may not be apparent, but you’ll soon wonder how you ever got by before.\nIt’s also helpful to think about the broader community that can support you along this journey. Learning alone can be discouraging and we strongly recommend that you tap into the diverse community of educators, mentors, bloggers, and friends that can help. Even you can create a community of practice!\n\n\n\n\n\n\n\n\n\n\n Exercise and discussion\n\nHow can you engage your peers to develop a shared workspace to learn new tools? What tools will you learn?"
  },
  {
    "objectID": "implement.html#fear-of-exposure",
    "href": "implement.html#fear-of-exposure",
    "title": "5  Addressing implementation barriers",
    "section": "5.3 Fear of exposure",
    "text": "5.3 Fear of exposure\n\n\n\n\n\n\n\n\n\n\n Challenge\n\nBeing open makes me nervous!\n\n Solution\n\nBeing open helps you collaborate, increases competitiveness, and creates a better scientific product!\nPracticing open science can feel like science in a fish bowl. Although this is kind of the goal, many view this transparency as a liability. Many fear having their ideas “scooped” or losing credibility because of greater exposure of mistakes. These are real concerns that require consideration when working towards more open workflows.\nIn conventional academic settings, competition for resources (e.g., via grant funding) is a real issue and being open can be seen as a risk to the competitive edge. We cannot dismiss this fact, but rather we can think about a lack of openness as a hindrance to forward progress and stifled creativity.\nThink about being open as a means to finding your next collaborator. Creating FAIR data opens the door for others to engage with your science. In fact, being open can increase the competitiveness of research proposals by building a stronger team that collaborates and shares data through better workflows.\nFirst time practitioners of open science also worry about the risk of “airing their dirty laundry”. By exposing the process and potential mistakes, many worry that their integrity as scientists may be questioned.\nThese fears are unfounded as the scientific process by definition is iterative. Hypotheses are supported or refuted through trial and error - if you’re getting your answer after one pass, you’re probably not doing it right. Making the process more transparent can help build trust as your collaborators can better appreciate how decisions and conclusions were made.\nMistakes in research are also very common, much more so than many people realize. By being open, it is true that mistakes are more visible, but this also provides a mechanism for fixing. Being open can lead to a better product by simply having more eyes on the process. It also helps normalize mistakes as part of the process - perfection is an unrealistic expectation.\n\n Exercise and discussion\n\nWhat are your personal concerns about adopting open science?"
  },
  {
    "objectID": "implement.html#what-does-it-mean-to-be-open",
    "href": "implement.html#what-does-it-mean-to-be-open",
    "title": "5  Addressing implementation barriers",
    "section": "5.4 What does it mean to be open?",
    "text": "5.4 What does it mean to be open?\n\n Challenge\n\nPeople and institutions define open differently!\n\n Solution\n\nUnderstand the context and demonstrate the value!\nAlso realize that open science can mean different things to different people. By extension, this also applies to institutions. We presented the five schools of open science to help conceptualize ideas and tools when we discuss what it means to different groups.\nThink about your employer and what they might care about if you advocate for adoption of open science. Do you need to convince them that there is value in being open? What is their value proposition? What are the hurdles to achieving openness at your institution?\nFor many institutions, being open may come with IT hurdles as you push for alternative software platforms. Working with IT staff to develop trust and comfort for new software may be your burden, but as always, it’s an investment in the future.\nMaybe there are legal contexts to being open. For example, Florida has the “Sunshine” law that makes all government communications public record. What does this mean for using new workflows in open science? Is this is an improvement or a liability (see previous section)?\nIf you’re an administrator or manager, maybe you’re the one that makes the call about being open. It’s important for you to create a culture that promotes and supports open science. Allow space and time for your staff to learn new skills. Realize that investing time in open science is an investment in the future.\n\n Exercise and discussion\n\nWhat does being open mean to you? What do you think being open means to your employer?"
  },
  {
    "objectID": "implement.html#something-is-better-than-nothing",
    "href": "implement.html#something-is-better-than-nothing",
    "title": "5  Addressing implementation barriers",
    "section": "5.5 Something is better than nothing",
    "text": "5.5 Something is better than nothing\n\n Challenge\n\nDoing all the things is impossible!\n\n Solution\n\nStart small, incremental progress is the name of the game!\nFirst time open science enthusiasts can be overwhelmed by the apparent need to check all the boxes on the open science list. There’s often a prevailing sentiment that you’re not doing open science unless you do all the things. This is simply not true. Just remember that doing something is a huge improvement over doing nothing.\nOpenness in science exists on a spectrum. Your goal should be incremental movement away from the completely closed end of the spectrum. Perhaps you set a goal of only accomplishing one open science task for a particular project. Maybe you start by developing a simple metadata text file or developing a data dictionary. Or maybe you make a commitment to try a new communication platform for collaborative engagement.\nChanneling this concept, Wilson et al. (2017) discuss “good enough practices” in scientific computing, acknowledging that very few of us are professionally trained in these disciplines and sometimes “good enough” is all we can ask for. Lowenberg et al. (2021) also advocate for simple adoption, rather than perfection, when it comes to data citation practices.\nAlso, be mindful of complacency (and apathy, at its very worst). Just because you think you’ve mastered a task doesn’t mean you can’t continue to learn. Always strive to improve yourself and the tools you use to be open. The fact that the toolbox is constantly evolving makes this a necessity.\nSo, be kind to yourself when learning new skills and realize that the first step will likely be frustration, but through frustration comes experience. The more comfortable you become with a task, the more likely you’ll attempt new tasks in the future. I promise you will see a return on your investment.\n\n Exercise and discussion\n\nWhat are some simple things you can do to begin adopting open science?\n\n\n\n\nLowenberg, Daniella, Rachael Lammey, Matthew B Jones, John Chodacki, and Martin Fenner. 2021. “Data Citation: Let’s Choose Adoption over Perfection.” Zenodo. https://doi.org/10.5281/zenodo.4701079.\n\n\nWilson, G., J. Bryan, K. Cranston, J. Kitzes, L. Nederbragt, and T. K. Teal. 2017. “Good Enough Practices in Scientific Computing.” PLoS Computational Biology 13 (6): e1005510. https://doi.org/10.1371/journal.pcbi.1005510."
  },
  {
    "objectID": "tools.html#slack",
    "href": "tools.html#slack",
    "title": "6  Additional tools for collaboration",
    "section": "6.1 Slack",
    "text": "6.1 Slack\n\n\n\n\n\n\n\n\n\nhttps://slack.com/\n\n What\n\nAn online messaging platform for internal communication. Conversations can be organized by topic (via channels) or you can send direct messages to one or more team members. You can have multiple workspaces for different groups.\n\n Pros\n\nAlleviate email overload through quick, informal messaging. Offers a fresh approach to online communication.\n\n Cons\n\nYet another thing to monitor. Free subscription limits archive of messages. Communication is limited to those in the same workspace."
  },
  {
    "objectID": "tools.html#trello",
    "href": "tools.html#trello",
    "title": "6  Additional tools for collaboration",
    "section": "6.2 Trello",
    "text": "6.2 Trello\n\n\n\n\n\n\n\n\n\nhttps://trello.com/\n\n What\n\nA Kanban style workflow organization platform. Can be used for personal organization or in teams. Card management allows you to assign due dates, add attachments, make checklists, assign tasks to yourself or team members, and label by themes.\n\n Pros\n\nEasy to use and can upgrade with “power-ups” for integration with other services (e.g., Google). Use across locations (e.g., from home or in the office) is easy because it’s based in a web browser.\n\n Cons\n\nNot entirely open because it’s only visible to yourself or those you explicitly invite. Free version is limited to only a handful of “power-ups”."
  },
  {
    "objectID": "tools.html#google-drive",
    "href": "tools.html#google-drive",
    "title": "6  Additional tools for collaboration",
    "section": "6.3 Google Drive",
    "text": "6.3 Google Drive\n\n\n\n\n\n\n\n\n\nhttps://google.com/drive\n\n What\n\nCloud-based platform for sharing documents, worksheets, slides, etc. Follows a familiar file-based structure that is common to most operating systems.\n\n Pros\n\nEasy to use and can be a very open space for collaboration. Fairly interoperable with different file formats. Some functionality with version control (i.e., ability to “revert” to previous versions and to view changes).\n\n Cons\n\nRequires a Google account and access can be tricky depending on institution. Even though some versioning is provided, the format can encourage poor file management. Who knows what Google is doing with your data."
  },
  {
    "objectID": "tools.html#office-365",
    "href": "tools.html#office-365",
    "title": "6  Additional tools for collaboration",
    "section": "6.4 Office 365",
    "text": "6.4 Office 365\n\n\n\n\n\n\n\n\n\nhttps://www.microsoft.com/en-us/microsoft-365\n\n What\n\nCloud-based platform for secure sharing of Microsoft documents, worksheets, slides, etc.\n\n Pros\n\nEasy to use and fully supports Microsoft products. Low barrier of inclusion to others that are already using Microsoft products.\n\n Cons\n\nRequires a Microsoft account and access can be tricky depending on institution. Maintains dependency on expensive Microsoft products that aren’t reproducible or interoperable. Very often used in closed workflows."
  },
  {
    "objectID": "tools.html#github",
    "href": "tools.html#github",
    "title": "6  Additional tools for collaboration",
    "section": "6.5 GitHub",
    "text": "6.5 GitHub\n\n\n\n\n\n\n\n\n\nhttps://github.com\n\n What\n\nCloud-based platform for sharing code with Git version control. Supports sharing of most file types, although code and text-based files are the primary use.\n\n Pros\n\nCollaborative and fully transparent work environment for files under version control. Supports workflow management through issue tracking and Kanban style project boards. Links to third-party platforms for archiving and DOI generation (e.g., Zenodo). Octocat mascot is super cute.\n\n Cons\n\nLearning curve is steep if you want to fully leverage version control. Not a formal data archival service by itself and file sizes are limited."
  },
  {
    "objectID": "setup.html#install-r-and-rstudio",
    "href": "setup.html#install-r-and-rstudio",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.1 Install R and RStudio",
    "text": "A.1 Install R and RStudio\nR and RStudio are separate downloads and installations. R is the underlying statistical computing software. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio.\nThanks to the USGS-R Training group and Data Carpentry for making their installation materials available. The following instructions come directly from their materials, with a few minor edits to help you get set up.\n\nA.1.1 Windows: Download and install R\nGo to CRAN and download the R installer for Windows. Make sure to choose the latest stable version (v4.2.3 as of April 2023).\nOnce the installer downloads, Right-click on it and select “Run as administrator”.\nType in your credentials and click yes (or if you don’t have administrator access have your IT rep install with Admin privileges).\n\n\n\n\n\nYou can click next through the standard dialogs and accept most defaults. But at the destination screen, please verify that it is installing it to C:\\Program Files\\R\n\n\n\n\n\nAt the “Select Components” screen, you can accept the default and install both 32-bit and 64-bit versions.\n\n\n\n\n\nAt this screen, uncheck ‘Create a desktop icon’ because non-admin users in Windows will be unable to delete it.\n\n\n\n\n\n\n\nA.1.2 Windows: Download and install RStudio\nDownload RStudio from here.\nAfter download, double-click the installer. It will ask for your administrator credentials to install (you might need to have your IT rep install again).\nAccept all the default options for the RStudio install.\n\n\n\n\n\n\n\nA.1.3 macOS: Download and install R\n\nDownload and install R from the CRAN website for Mac here.\nSelect the .pkg file for the latest R version\nDouble click on the downloaded file to install R\nIt is also a good idea to install XQuartz (needed by some packages)\n\n\n\nA.1.4 macOS: Download and install RStudio\n\nGo to the RStudio download page\nUnder Installers select the appropriate RStudio download file for macOS\nDouble click the file to install RStudio\n\n\n\nA.1.5 Check Install\nOnce installed, RStudio should be accessible from the start menu. Start up RStudio. Once running it should look something like this:"
  },
  {
    "objectID": "setup.html#install-quarto",
    "href": "setup.html#install-quarto",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.2 Install Quarto",
    "text": "A.2 Install Quarto\nA visual editor for Quarto is installed with RStudio. However, you’ll need to install Quarto CLI to make full use of its features.\nNavigate to https://quarto.org/docs/get-started/. You’ll see a screen that looks like this:\n\n\n\n\n\nSelect the download appropriate for your operating system (Windows is the big blue button). After the file is downloaded, navigate to the folder containing the file, double-click to install, and accept the default settings at the prompts.\nAfter installation is done, open RStudio (or close and open again) and select the Terminal tab. This tab is located on the bottom-left pane, next to the Console tab. Type quarto check at the prompt and press enter. You should see something like this if installation was successful."
  },
  {
    "objectID": "setup.html#create-github-account",
    "href": "setup.html#create-github-account",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.3 Create GitHub account",
    "text": "A.3 Create GitHub account\nOpen a web browser and enter the url https://github.com. On the top-right, you should see a button to sign up. Click the button and register an account by choosing an email, username, and password."
  },
  {
    "objectID": "setup.html#install-git-optional",
    "href": "setup.html#install-git-optional",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.4 Install Git (optional)",
    "text": "A.4 Install Git (optional)\nAfter you’ve registered a new GitHub account, you can install the Git software on your computer. Git is version control software used by RStudio that allows you to access GitHub. Open the url https://git-scm.com/book/en/v2/Getting-Started-Installing-Git and follow the instructions for your operating system.\nAfter Git is installed, open RStudio (or close and open again) to verify the installation. You should see a new “Git” tab located in the top-right pane of RStudio.\n\n\n\n\n\n\nA.4.1 Make sure RStudio can talk to GitHub via Git\nThe next step can be a bit tricky, but is essential if you want to access your GitHub using RStudio and Git. First, install the usethis R package in RStudio.\n\ninstall.packages(\"usethis\")\n\nYou must let Git know who you are and that you have permission to write to a GitHub repository. First, let Git know who you are, where you enter your user name and email associated with the account from the previous step.\n\nusethis::use_git_config(user.name=\"Jane Doe\", user.email=\"jane@example.org\")\n\nNext, you need to setup a personal access token (PAT) that defines the permissions to write to a repository. This can be done as follows:\n\nusethis::create_github_token()\n\nThen follow the remaining prompts to complete the PAT creation. A more thorough explanation can be found here."
  },
  {
    "objectID": "setup.html#this-is-hard",
    "href": "setup.html#this-is-hard",
    "title": "Appendix A — Setup for the workshop",
    "section": "A.5 This is hard!",
    "text": "A.5 This is hard!\nIf you have trouble installing any of the software prior to the workshop, you can use use RStudio in the cloud on the Posit website. This is only a backup option and we strongly encourage you to troubleshoot the installation when able.\nTo use RStudio in the cloud, copy this link and paste it in a web browser: https://posit.cloud/content/5775087\nIf you do not have a Posit Cloud account, you will see this screen when you first visit the URL:\n\n\n\n\n\n\nYou can setup an account for free using a login you create or through a third-party (Google or GitHub).\nAfter your account is setup, you should a screen that looks like this:\n\n\n\n\n\n\nYou’ll see that this is a TEMPORARY COPY under your account. Make it permanent by clicking the button on top. This will save any changes you make to this project under your account."
  },
  {
    "objectID": "rintro.html#rstudio",
    "href": "rintro.html#rstudio",
    "title": "Appendix B — Introduction to R",
    "section": "B.1 RStudio",
    "text": "B.1 RStudio\nRStudio is the go-to Interactive Development Environment (IDE) for R. Rstudio includes many features to improve the user’s experience.\nLet’s get familiar with RStudio.\n\nB.1.1 Open R and RStudio\nFind the RStudio shortcut on your computer and fire it up. You should see something like this:\n\n\n\n\n\nThere are four panes in RStudio:\n\nSource: Your primary window for writing code to send to the console, this is where you write and save R “scripts”\nConsole: This is where code is executed in R\nEnvironment, History, etc.: A tabbed window showing your working environment, code execution history, and other useful things\nFiles, plots, etc.: A tabbed window showing a file explorer, a plot window, list of installed packages, help files, and viewer\n\n\n\nB.1.2 Scripting\nIn most cases, you will not enter and execute code directly in the console. Code can be written in a script and then sent directly to the console.\nOpen a new script from the File menu…\n\n\n\n\n\n\n\nB.1.3 Executing code in RStudio\nAfter you write code in an R script, it can be sent to the Console to run the code. There are two ways to do this. First, you can hit the Run button at the top right of the scripting window. Second, you can use ctrl+enter (cmd+enter on a Mac). Either option will run the line(s) of script that are selected."
  },
  {
    "objectID": "rintro.html#r-language-fundamentals",
    "href": "rintro.html#r-language-fundamentals",
    "title": "Appendix B — Introduction to R",
    "section": "B.2 R language fundamentals",
    "text": "B.2 R language fundamentals\nR is built around functions. The basic syntax of a function follows the form: function_name(arg1, arg2, ...).\nWith the base install, you will gain access to many functions (2344, to be exact). Some examples:\n\n# print\nprint(\"hello world!\")\n\n[1] \"hello world!\"\n\n# sequence\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# random numbers\nrnorm(100, mean = 10, sd = 2)\n\n  [1]  7.832059  9.030275  7.521228 12.616918 13.215175 11.045583  8.824025\n  [8]  9.164448 15.658834  7.723422 10.385766 11.286373 10.844230  9.308130\n [15]  9.866230 11.626407  9.609709  9.832751 13.318156 12.911296 12.110288\n [22]  8.700670  9.963275 12.207635 10.142770  9.797164  9.131849  8.132225\n [29]  8.313162  9.666926 11.865254  7.049855 11.920676 10.552569 14.003112\n [36]  8.294335 10.562336 13.306502  9.975742  8.215969 10.411863 10.345312\n [43] 10.371059 11.354884 11.014762 10.599500  9.694165  9.521077 11.210059\n [50]  9.253853  9.052991  8.932931  4.993988 13.427047  9.940464 10.103326\n [57]  9.106110 12.112059 10.201490 10.390663 10.944361 12.970049  9.615033\n [64]  8.311015  7.254915  8.834448 12.106896  7.206025  9.504727  9.655150\n [71] 10.816777 10.395910  9.108460  8.554659  8.465858  7.032808  5.473028\n [78]  9.122728 14.609916  8.737284  9.251098 10.150334 10.498301 12.970926\n [85]  9.114530 11.628201  8.796504  8.486354  8.413195  9.075506 14.237561\n [92] 10.006961 10.475544 12.164507  5.407657  5.470693  8.154651  9.003100\n [99] 10.888977 10.604886\n\n# average \nmean(rnorm(100))\n\n[1] -0.008148899\n\n# sum\nsum(rnorm(100))\n\n[1] -12.39607\n\n\nVery often you will see functions used like this:\n\nmy_random_sum &lt;- sum(rnorm(100))\n\nThe first part of the line is the name of an object that you make up. The second bit, &lt;-, is the assignment operator. This tells R to take the result of sum(rnorm(100)) and store it in an object named, my_random_sum. It is stored in the environment and can be used by just executing it’s name in the console.\n\nmy_random_sum\n\n[1] -9.990494\n\n\n\nB.2.1 What is the environment?\nThere are two outcomes when you run code. First, the code will simply print output directly in the console. Second, there is no output because you have stored it as a variable using &lt;-. Output that is stored is saved in the environment. The environment is the collection of named objects that are stored in memory for your current R session."
  },
  {
    "objectID": "rintro.html#packages",
    "href": "rintro.html#packages",
    "title": "Appendix B — Introduction to R",
    "section": "B.3 Packages",
    "text": "B.3 Packages\nThe base installation of R is quite powerful. Packages allow you to include new methods for use in R.\n\nB.3.1 CRAN\nMany packages are available on CRAN, The Comprehensive R Archive Network. This is where you download R and also where most will gain access to packages. As of 2023-05-08, there are 19457 packages on CRAN!\n\n\nB.3.2 Installing packages\nWhen a package gets installed, that means the source code is downloaded and put into your library. A default library location is set for you.\nWe use the install.packages() function to download and install a package. Here, we install the readxl package, used below, which is used to upload data from and Excel file.\n\ninstall.packages(\"readxl\")\n\nYou should see some text in the R console showing progress of the installation and a prompt after installation is done.\nAfter installation, you can load a package using the library() function. This makes all functions in a package available for you to use.\n\nlibrary(readxl)\n\nAn important aspect of packages is that you only need to download them once, but every time you start RStudio you need to load them with the library() function."
  },
  {
    "objectID": "rintro.html#data-structures-in-r",
    "href": "rintro.html#data-structures-in-r",
    "title": "Appendix B — Introduction to R",
    "section": "B.4 Data structures in R",
    "text": "B.4 Data structures in R\nNow we can talk about R data structures. Simply put, a data structure is a way for programming languages to handle information storage.\n\nB.4.1 Vectors (one-dimensional data)\nThe basic data format in R is a vector - a one-dimensional grouping of elements that have the same type. These are all vectors and they are created with the c (concatenate) function:\n\ndbl_var &lt;- c(1, 2.5, 4.5)\nint_var &lt;- c(1L, 6L, 10L)\nlog_var &lt;- c(TRUE, FALSE, T, F)\nchr_var &lt;- c(\"a\", \"b\", \"c\")\n\nThe four types of vectors are double (or numeric), integer, logical, and character. The following functions can return useful information about the vectors:\n\nclass(dbl_var)\n\n[1] \"numeric\"\n\nlength(log_var)\n\n[1] 4\n\n\n\n\nB.4.2 Data frames (two-dimensional data)\nA collection of vectors represented as one data object are often described as two-dimensional data, like a spreadsheet, or in R speak, a data frame. Here’s a simple example:\n\nltrs &lt;- c(\"a\", \"b\", \"c\")\nnums &lt;- c(1, 2, 3)\nlogs &lt;- c(T, F, T)\nmydf &lt;- data.frame(ltrs, nums, logs)\nmydf\n\n  ltrs nums  logs\n1    a    1  TRUE\n2    b    2 FALSE\n3    c    3  TRUE\n\n\nThe only constraints required to make a data frame are:\n\nEach column (vector) contains the same type of data\nThe number of observations in each column is equal."
  },
  {
    "objectID": "rintro.html#getting-your-data-into-r",
    "href": "rintro.html#getting-your-data-into-r",
    "title": "Appendix B — Introduction to R",
    "section": "B.5 Getting your data into R",
    "text": "B.5 Getting your data into R\nIt is the rare case when you manually enter your data in R. Most data analysis workflows typically begin with importing a dataset from an external source. We’ll be using read_excel() function from the readxl package.\nWe can import the ExampleSites.xlsx dataset as follows. Note the use of a relative file path. You can see what R is using as your “working directory” using the getwd() function.\n\nsitdat &lt;- read_excel(\"data/ExampleSites.xlsx\")\n\nLet’s explore the dataset a bit.\n\n# get the dimensions\ndim(sitdat)\n\n[1] 11  5\n\n# get the column names\nnames(sitdat)\n\n[1] \"Monitoring Location ID\"        \"Monitoring Location Name\"     \n[3] \"Monitoring Location Latitude\"  \"Monitoring Location Longitude\"\n[5] \"Location Group\"               \n\n# see the first six rows\nhead(sitdat)\n\n# A tibble: 6 × 5\n  `Monitoring Location ID` `Monitoring Location Name` Monitoring Location Lati…¹\n  &lt;chr&gt;                    &lt;chr&gt;                                           &lt;dbl&gt;\n1 ABT-026                  Rte 2, Concord                                   42.5\n2 ABT-062                  Rte 62, Acton                                    42.4\n3 ABT-077                  Rte 27/USGS, Maynard                             42.4\n4 ABT-144                  Rte 62, Stow                                     42.4\n5 ABT-237                  Robin Hill Rd, Marlboro                          42.3\n6 ABT-301                  Rte 9, Westboro                                  42.3\n# ℹ abbreviated name: ¹​`Monitoring Location Latitude`\n# ℹ 2 more variables: `Monitoring Location Longitude` &lt;dbl&gt;,\n#   `Location Group` &lt;chr&gt;\n\n# get the overall structure\nstr(sitdat)\n\ntibble [11 × 5] (S3: tbl_df/tbl/data.frame)\n $ Monitoring Location ID       : chr [1:11] \"ABT-026\" \"ABT-062\" \"ABT-077\" \"ABT-144\" ...\n $ Monitoring Location Name     : chr [1:11] \"Rte 2, Concord\" \"Rte 62, Acton\" \"Rte 27/USGS, Maynard\" \"Rte 62, Stow\" ...\n $ Monitoring Location Latitude : num [1:11] 42.5 42.4 42.4 42.4 42.3 ...\n $ Monitoring Location Longitude: num [1:11] -71.4 -71.4 -71.4 -71.5 -71.6 ...\n $ Location Group               : chr [1:11] \"Assabet\" \"Assabet\" \"Assabet\" \"Assabet\" ...\n\n\nYou can also view a dataset in a spreadsheet style using the View() function:\n\nView(sitdat)"
  },
  {
    "objectID": "rintro.html#summary",
    "href": "rintro.html#summary",
    "title": "Appendix B — Introduction to R",
    "section": "B.6 Summary",
    "text": "B.6 Summary\nIn this intro we learned about R and Rstudio, some of the basic syntax and data structures in R, and how to import files. You’ll be able to follow the rest of the workshop with this knowledge. View the Resources page for additional training materials."
  },
  {
    "objectID": "resources.html#open-science-websites",
    "href": "resources.html#open-science-websites",
    "title": "Appendix C — Resources",
    "section": "C.1 Open Science Websites",
    "text": "C.1 Open Science Websites\n\nNCEAS Open Science for Synthesis workshop\nNCEAS Reproducible Research Techniques\nOpen Science Foundation open science workshop\nOpenscapes\nOpenscapes Champions Lesson Series\nSupercharge your research: A 10 week plan for open data science\nROpenSci guidance on creating a Code of Conduct\nNOAA Reproducible Reporting with R\nPeerJ collection on practical data science"
  },
  {
    "objectID": "resources.html#data-management-tools",
    "href": "resources.html#data-management-tools",
    "title": "Appendix C — Resources",
    "section": "C.2 Data Management Tools",
    "text": "C.2 Data Management Tools\n\nEnvironmental Data Initiative Data Management Resources\nUniversity of California DMPTool\nUS Geological Survey resources for Metadata Creation\nELIXIR and others Data Stewardship Wizard\nTBEP Data Management SOP"
  },
  {
    "objectID": "resources.html#tbep-r-trainings",
    "href": "resources.html#tbep-r-trainings",
    "title": "Appendix C — Resources",
    "section": "C.3 TBEP R Trainings",
    "text": "C.3 TBEP R Trainings\n\nPeconic Estuary Program R training, recording\nTBEP June 2020 R training, recordings\nWriting functions in R\nR package development workflow\nA soft introduction to Shiny"
  },
  {
    "objectID": "resources.html#r-lessons-tutorials",
    "href": "resources.html#r-lessons-tutorials",
    "title": "Appendix C — Resources",
    "section": "C.4 R Lessons & Tutorials",
    "text": "C.4 R Lessons & Tutorials\n\nSoftware Carpentry: R for Reproducible Scientific Analysis\nData Carpentry: Geospatial Workshop\nData Carpentry: R for Data Analysis and Visualization of Ecological Data\nData Carpentry: Data Organization in Spreadsheets\nR for Water Resources Data Science\nRStudio Webinars, many topics\nR For Cats: Basic introduction site, with cats!\nTopical cheatsheets from RStudio, also viewed from the help menu\nCheatsheet from CRAN of base R functions\nTotally awesome R-related artwork by Allison Horst\nColor reference PDF with text names, Color cheatsheet PDF from NCEAS"
  },
  {
    "objectID": "resources.html#r-ebookscourses",
    "href": "resources.html#r-ebookscourses",
    "title": "Appendix C — Resources",
    "section": "C.5 R eBooks/Courses",
    "text": "C.5 R eBooks/Courses\n\nJenny Bryan’s Stat545.com\nGarrett Grolemund and Hadley Wickham’s R For Data Science\nChester Ismay and Albert Y. Kim’s Modern DiveR\nJulia Silge and David Robinson Text Mining with R\nHadley Wickham’s Advanced R\nHadley Wickham’s R for Data Science\nYihui Xie R Markdown: The Definitive Guide\nWinston Chang R Graphics Cookbook\nWegman et al. Remote Sensing and GIS for Ecologists: Using Open Source Software\nLovelace et al. Geocomputation with R\nEdszer Pebesma and Roger Bivand Spatial Data Science"
  },
  {
    "objectID": "resources.html#gitgithub",
    "href": "resources.html#gitgithub",
    "title": "Appendix C — Resources",
    "section": "C.6 Git/Github",
    "text": "C.6 Git/Github\n\nJenny Bryan’s Happy Git and Github for the useR\nGit and GitHub for the Casual User\nCoding Club Intro to Github"
  },
  {
    "objectID": "codeofconduct.html#our-pledge",
    "href": "codeofconduct.html#our-pledge",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.1 Our Pledge",
    "text": "D.1 Our Pledge\nWe as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "codeofconduct.html#our-standards",
    "href": "codeofconduct.html#our-standards",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.2 Our Standards",
    "text": "D.2 Our Standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "codeofconduct.html#enforcement-responsibilities",
    "href": "codeofconduct.html#enforcement-responsibilities",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.3 Enforcement Responsibilities",
    "text": "D.3 Enforcement Responsibilities\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "codeofconduct.html#scope",
    "href": "codeofconduct.html#scope",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.4 Scope",
    "text": "D.4 Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "codeofconduct.html#enforcement",
    "href": "codeofconduct.html#enforcement",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.5 Enforcement",
    "text": "D.5 Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at mbeck@tbep.org. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "codeofconduct.html#enforcement-guidelines",
    "href": "codeofconduct.html#enforcement-guidelines",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.6 Enforcement Guidelines",
    "text": "D.6 Enforcement Guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\nD.6.1 1. Correction\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\nD.6.2 2. Warning\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\nD.6.3 3. Temporary Ban\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\nD.6.4 4. Permanent Ban\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "codeofconduct.html#attribution",
    "href": "codeofconduct.html#attribution",
    "title": "Appendix D — Contributor Covenant Code of Conduct",
    "section": "D.7 Attribution",
    "text": "D.7 Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Broman, K. W., and K. H. Woo. 2018. “Data Organization in\nSpreadsheets.” The American Statistician 72 (1): 2–10.\nhttps://doi.org/10.1080/00031305.2017.1375989.\n\n\nFecher, B., and S. Friesike. 2014. “Open Science: One Term, Five\nSchools of Thought.” In Opening Science, 17–47.\nSpringer, Cham.\n\n\nKnuth, Donald Ervin. 1984. “Literate Programming.” The\nComputer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nLowenberg, Daniella, Rachael Lammey, Matthew B Jones, John Chodacki, and\nMartin Fenner. 2021. “Data Citation: Let’s Choose Adoption over\nPerfection.” Zenodo. https://doi.org/10.5281/zenodo.4701079.\n\n\nMichener, W. K., J. W. Brunt, J. J. Helly, T. B. Kirchner, and S. G.\nStafford. 1997. “Nongeospatial Metadata for the Ecological\nSciences.” Ecological Applications 7 (1): 330–42.\nhttps://doi.org/https://doi.org/10.1890/1051-0761(1997)007[0330:NMFTES]2.0.CO;2.\n\n\nShafland, Paul L., and James M. Pestrak. 1982. “Lower Lethal\nTemperatures for Fourteen Non-Native Fishes in Florida.”\nEnvironmental Biology of Fishes 7 (2): 149–56. https://doi.org/10.1007/bf00001785.\n\n\nWickham, H. 2014. “Tidy Data.” Journal of Statistical\nSoftware 59 (10): 1–23. https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, H., M. Averick, J. Bryan, W. Chang, L. D’Agostino McGowan, R.\nFrançois, G. Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source\nSoftware 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, H., and G. Grolemund. 2017. R for Data Science.\nSebastopol, California: O’Reilly.\n\n\nWilkinson, M. D., M. Dumontier, I. J. Aalbersberg, G. Appleton, M.\nAxton, A. Baak, N. Blomberg, et al. 2016. “The FAIR Guiding\nPrinciples for Scientific Data Management and Stewardship.”\nScientific Data 3 (160018). https://doi.org/10.1038/sdata.2016.18.\n\n\nWilson, G., J. Bryan, K. Cranston, J. Kitzes, L. Nederbragt, and T. K.\nTeal. 2017. “Good Enough Practices in Scientific\nComputing.” PLoS Computational Biology 13 (6): e1005510.\nhttps://doi.org/10.1371/journal.pcbi.1005510.\n\n\nZiemann, M., Y. Eren, and A. El-Osta. 2016. “Gene Name Errors Are\nWidespread in the Scientific Literature.” Genome Biology\n17 (1): 1–3. https://doi.org/10.1186/s13059-016-1044-7."
  }
]